# -*- coding: utf-8 -*-
"""RNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/156thyv-S5vqnXyYrOEvGzgqtFNOnIggd
"""



import numpy as np
import tensorflow as tf
import shap

from tensorflow.keras.datasets import imdb
tf.compat.v1.disable_v2_behavior()

print(tf.__version__)

words=20000
max_length=100

(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=words)
"""Padding the Text"""
x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_length)
x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_length)

word_size=words
word_size
embed_size=128

imdb_model=tf.keras.Sequential()
# Embedding Layer
imdb_model.add(tf.keras.layers.Embedding(word_size, embed_size, input_shape=(x_train.shape[1],)))
# LSTM Layer
imdb_model.add(tf.keras.layers.LSTM(units=128, activation='tanh'))
# Output Layer
imdb_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))
imdb_model.summary()

imdb_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])

imdb_model.fit(x_train, y_train, epochs=5, batch_size=128)
test_loss, test_acurracy = imdb_model.evaluate(x_test, y_test)
print("Test accuracy: {}".format(test_acurracy))




# we use the first 100 training examples as our background dataset to integrate over
explainer = shap.DeepExplainer(imdb_model, x_train[:100])

# explain the first 10 predictions
# explaining each prediction requires 2 * background dataset size runs
shap_values = explainer.shap_values(x_test[:50])

# init the JS visualization code
shap.initjs()

# transform the indexes to words
import numpy as np
words = imdb.get_word_index()
# print(len(words))
num2word = {}
for w in words.keys():
    num2word[words[w]] = w
x_test_words = np.stack([np.array(list(map(lambda x: num2word.get(x, "NONE"), x_test[i]))) for i in range(10)])

# plot the explanation of the first prediction
# Note the model is "multi-output" because it is rank-2 but only has one column
shap.force_plot(explainer.expected_value[0], shap_values[0][0], x_test_words[0])

def fai_cls(model,x,coefs,base):
    pred_class = np.argmax(model.predict(x.reshape(1,-1)), axis=1)[0]
    ar = np.argsort(-coefs)  #argsort returns indexes of values sorted in increasing order; so do it for negated array
    pred_probs = np.zeros(x.shape[0])
    for ind in np.nditer(ar):
        x_copy = x.copy()
        x_copy[ind] = base[ind]
        x_copy_pr = model.predict(x_copy.reshape(1,-1))
        pred_probs[ind] = x_copy_pr[0][pred_class]
        # print(pred_probs)
        # print(pred_class)

    return -np.corrcoef(coefs, pred_probs)[0,1]

import matplotlib.pyplot as pp

model = imdb_model
base = np.zeros(shape=(100))
f = []
for i in range(20):
  x = x_test[i]
  coefs = shap_values[0][i]
  f.append(fai_cls(model,x,coefs,base))

pp.plot(f,'-o')
pp.show()

import matplotlib.pyplot as pp
pp.plot(f,'-o')
pp.show()

np.mean(np.array(f))

x_test_words[4]
x_test = x_test.astype(str)

y_test[0]

shap.initjs()
shap.force_plot(explainer.expected_value[0], shap_values[0][4], x_test_words[4],matplotlib = True)

imdb_model.predict(np.transpose(x_test[4].reshape(-1,1)))

def monotonicity_metric(model, x, coefs, base):

    #find predicted class
    pred_class = np.argmax(model.predict(x.reshape(1,-1)), axis=1)[0]

    x_copy = base.copy()

    #find indexs of coefficients in increasing order of value
    ar = np.argsort(coefs)
    pred_probs = np.zeros(x.shape[0])
    for ind in np.nditer(ar):
        x_copy[ind] = x[ind]
        x_copy_pr = model.predict(x_copy.reshape(1,-1))
        pred_probs[ind] = x_copy_pr[0][pred_class]

    return np.all(np.diff(pred_probs[ar]) >= 0)

def monotonicity_metric_txt(model, x, coefs, base):
    pred_class = np.argmax(model.predict(x.reshape(1,-1)), axis=1)[0]

    x_copy = base.copy()
    ar = np.argsort(coefs)
    isPos = [False for i in range(len(ar))]
    pred_tss = np.zeros(x.shape[0])
    
    for ind in np.nditer(ar):
        if coefs[ind]<0:
            isPos[ind] = False
        else:
            isPos[ind] = True
        x_copy[ind] = x[ind]
        x_copy_pr = model.predict(x_copy.reshape(1,-1))
        pred_tss[ind] = x_copy_pr
    diff = np.diff(pred_tss[ar])
    final_ = []
    for i in range(len(diff)):
        if isPos[i] == False and diff[i] < 0:
            final_.append(True)
        elif isPos[i] == True and diff[i] >=0:
            final_.append(True)
        else:
            final_.append(False)
    return any(final_)

model = imdb_model
base = np.zeros(shape=(100))
m = []
for i in range(20):
  x = x_test[i]
  coefs = shap_values[0][i]
  m.append(monotonicity_metric_txt(model,x,coefs,base))
print(m)

# """LIME"""

# # Commented out IPython magic to ensure Python compatibility.
# import seaborn as sns
# # %matplotlib inline
# from collections import OrderedDict
# from lime.lime_text import LimeTextExplainer

# class_names = ['negative', 'positive']

# # x_test_words[0][50]
# x_test_words = x_test_words.astype(str)

# x_test_0 = ' '.join(x_test_words[0])
# t=[]
# t.append(x_test_0)
# t

# x_test_0_raw = r'{}'.format(x_test_0)
# x_test_0_raw

# t=[]
# t.append(x_test_0_raw)

# myString = list(x_test_0)
# type(list(x_test)[0])

# def getTextCount(data):
#   d = defaultdict(int)
#   splited = data.split()
#   for s in splited:
#     d[s]+= 1
#   count = []
  
# explainer = LimeTextExplainer(class_names=class_names)
# print(x_test[0])
# print(np.transpose(x_test[4].reshape(-1, 1)).shape)
# idx = 4
# print(x_test[1].shape)
# predict_fn = lambda x: imdb_model.predict()
# explanation = explainer.explain_instance(' '.join(x_test_words[4]), predict_fn, num_features=100,num_samples=1,top_labels=2)

# weights = OrderedDict(explanation.as_list())
# lime_weights = pd.DataFrame({'words': list(weights.keys()), 'weights': list(weights.values())})

# sns.barplot(x="words", y="weights", data=lime_weights);
# plt.xticks(rotation=45)
# plt.title('Sample {} features weights given by LIME'.format(idx));

# explainer = LimeTextExplainer(class_names=class_names)
# explanation = explainer.explain_instance(text_sample, pipeline.predict_proba, num_features=10)

# weights = OrderedDict(explanation.as_list())
# lime_weights = pd.DataFrame({'words': list(weights.keys()), 'weights': list(weights.values())})

# sns.barplot(x="words", y="weights", data=lime_weights);
# plt.xticks(rotation=45)
# plt.title('Sample {} features weights given by LIME'.format(idx));

# def faithfulness_metric_new(model, x, coefs, base):
#     predt = model.predict(np.transpose(x.reshape(-1,1)))
#     ar = np.argsort(coefs) 
#     pred_ts = np.zeros(x.shape[0])
#     diff = []
#     for ind in np.nditer(ar):
#         x_copy = x.copy()
#         d = x_copy[ind]-base[ind]
#         if d<0:
#             diff.append(-1)
#         else:
#             diff.append(1)
#         x_copy[ind] = base[ind]
#         x_copy_ts = model.predict(np.transpose(x_copy.reshape(-1,1)))
#         pred_ts[ind] = x_copy_ts - predt
    
#     return -np.corrcoef(coefs, pred_ts)[0,1]



# x_train[:100].shape



# imdb_model.predict(np.transpose(x_test[0].reshape(-1,1)))

# x_test[0]

# x_test_words[0]



# words = imdb.get_word_index()
# num2word = {}
# for w in words.keys():
#     num2word[words[w]] = w
# x_test_words = np.stack([np.array(list(map(lambda x: num2word.get(x, "NONE"), x_test[i]))) for i in range(10)])

# np.array(shap_values[0][0]).shape

# np.array(shap_values).shape

# x_test[0].shape

# explainer.expected_value

# faithfulness_metric_new(imdb_model, x_train[:100],shap_values,)

# # Commented out IPython magic to ensure Python compatibility.
# import seaborn as sns
# # %matplotlib inline
# from collections import OrderedDict
# from lime.lime_text import LimeTextExplainer

# explainer = LimeTextExplainer(class_names=class_names)
# explanation = explainer.explain_instance(text_sample, pipeline.predict_proba, num_features=10)

# weights = OrderedDict(explanation.as_list())
# lime_weights = pd.DataFrame({'words': list(weights.keys()), 'weights': list(weights.values())})

# sns.barplot(x="words", y="weights", data=lime_weights);
# plt.xticks(rotation=45)
# plt.title('Sample {} features weights given by LIME'.format(idx









# from keras.preprocessing.text import one_hot

# sentence=['Fast cars are good',
#           'Football is a famous sport',
#           'Be happy Be positive']

# vocab_size=1000

# encoded_docs=[one_hot(d,vocab_size) for d in sentence]

# from keras.preprocessing.sequence import pad_sequences
# from keras.models import Sequential
# from keras.layers import Embedding

# import numpy as np

# embedding_length=5
# max_length=10

# encoded_docs=pad_sequences(encoded_docs,truncating='post',padding='post',maxlen=max_length)
# print(encoded_docs)

# model=Sequential()
# model.add(Embedding(vocab_size,embedding_length,input_length=max_length))
# model.compile('rmsprop','mse')
# model.summary()
# output=model.predict(encoded_docs)
# print(output.shape)
# print(output)

# def monotonicity_metric(model, x, coefs, base):

#     """ This metric measures the effect of individual features on model performance by evaluating the effect on
#     model performance of incrementally adding each attribute in order of increasing importance. As each feature
#     is added, the performance of the model should correspondingly increase, thereby resulting in monotonically
#     increasing model performance. [#]_
#     References:
#         .. [#] `Ronny Luss, Pin-Yu Chen, Amit Dhurandhar, Prasanna Sattigeri, Karthikeyan Shanmugam, and
#            Chun-Chen Tu. Generating Contrastive Explanations with Monotonic Attribute Functions. CoRR abs/1905.13565. 2019.
#            <https://arxiv.org/pdf/1905.12698.pdf>`_
#     Args:
#         model: Trained classifier, such as a ScikitClassifier that implements
#             a predict() and a predict_proba() methods.
#         x (numpy.ndarray): row of data.
#         coefs (numpy.ndarray): coefficients (weights) corresponding to attribute importance.
#         base ((numpy.ndarray): base (default) values of attributes
#     Returns:
#         bool: True if the relationship is monotonic.
#     """
#     #find predicted class
#     pred_class = np.argmax(model.predict_proba(x.reshape(1,-1)), axis=1)[0]

#     x_copy = base.copy()

#     #find indexs of coefficients in increasing order of value
#     ar = np.argsort(coefs)
#     pred_probs = np.zeros(x.shape[0])
#     for ind in np.nditer(ar):
#         x_copy[ind] = x[ind]
#         x_copy_pr = model.predict_proba(x_copy.reshape(1,-1))
#         pred_probs[ind] = x_copy_pr[0][pred_class]

#     return np.all(np.diff(pred_probs[ar]) >= 0)